Advanced Tabular Data Manipulation	
========================================================
author: Alejandro Schuler, adapted from Steve Bagley and based on R for Data Science by Hadley Wickham
date: July 2020
transition: none
width: 1680
height: 1050

- compute cumulative, offset, and sliding-window transformations
- simultaneously transform or summarize multiple columns
- transform between long and wide data formats
- combine multiple data frames using joins on one or more columns

```{r include=FALSE}
## better font size for slides
library(tidyverse)
theme_set(theme_grey(base_size = 22))
opts_chunk$set(collapse=TRUE,tidy=FALSE,prompt=FALSE,comment=NA,cache=FALSE)
opts_chunk$set(error=TRUE,warning=TRUE,message=TRUE)
```
<style>
.small-code pre code {
  font-size: 0.5em;
}
</style>

Window transformations
===
type: section

Offsets
===
incremental: true

- `lead()` and `lag()` return either forward- or backward-shifted versions of their input vectors
```{r}
lead(c(1,2,3))
lag(c(1,2,3))
```

- This is most useful to compute offsets
```{r, tidy=F}
scores = tibble(
  day = c(1,2,3,4),
  score = c(72, 87, 94, 99)
)
```

```{r, tidy=F}
scores %>%
  mutate(daily_improvement = score - lag(score))
```

Exercise: multiple offsets
===
type: prompt

```{r, tidy=F}
scores = tibble(
  week = c(1,1,2,2,3,3,4,4),
  weekday = c("M","F","M","F","M","F","M","F"),
  score = c(72, 71, 80, 87, 94, 82, 99, 98)
)
```
Let's say you want to compute the improvement in scores within weekdays from one week to the next
(i.e. comparing week 1 Monday to week 2 Monday and week 1 Friday to week 2 Friday)

1. Figure out a way to do this using `lead()` or `lag()` in a single `mutate()` statement (hint: check the documentation).
2. Figure out a different way to do this with `group_by()` instead. Which seems more natural or robust to you? Why?
3. In both solutions you end up with some `NA`s since the "week 0" scores are unknown. If we wanted to assume that the week 0 scores would be the same as the week 1 scores, how might we modify our code to reflect that in order to make sure we don't get `NA`s in the result?

Rolling functions
===

- `slide_vec` applies a function using a sliding window across a vector (sometimes called a "rolling" function)

```{r}
library("slider")
numbers = c(9,6,8,4,7,3,8,4,2,1,3,2)
slide_vec(numbers, sum, .after=3, .step=2)
```

- the `.after` argument specifies how many elements after the "index" element are included in the rolling window
- `.step` specifies how to move from one index element to the next

***

![](https://www.oreilly.com/library/view/introduction-to-apache/9781491977132/assets/itaf_0406.png)

Rolling functions
===
```{r, tidy=F}
profits = tibble(
  day = c(1,2,3,4),
  profit = c(12, 40, 19, 13)
)
```

- `.before` is the backward-looking equivalent of `.after`

```{r, tidy=F}
profits %>%
  mutate(avg_2_day_profit = slide_vec(profit, mean, .before=1))
```

Cumulative functions
===
incremental: true

- A cumulative function is like a rolling window function except that the window expands with each iteration instead of shifting over
- For example, `cumsum` takes the cumulative sum of a vector. See `?cumsum` for similar functions
```{r}
cumsum(c(1,2,3))
```

```{r, tidy=F}
profits = tibble(
  day = c(1,2,3,4),
  profit = c(12, 40, 19, 13)
)
```

```{r, tidy=F}
profits %>%
  mutate(best_day_to_date = cumsum(profit))
```

Turning any function into a cumulative function
===

- you can use `slider::slide_vec()` to turn any function that accepts a vector and returns a number into a cumulative function
- Use `.before=Inf` to achieve this
```{r, tidy=F}
library(slider) # imports slide_vec() function

profits %>%
  mutate(profit_to_date = slide_vec(profit, sum, .before=Inf))
```

- it is usually better (computationally faster) to use a built-in cumulative function (e.g. `cumsum()`), but if none exists this is a great solution

Turning any function into a cumulative function
===
- If the function you want to transform takes additional arguments, you can give those to `slide_vec` and it will pass them through for you
```{r, tidy=F}
tibble(
  day = c(1,2,3,4),
  profit = c(12, 40, NA, 13)
) %>%
  mutate(profit_to_date = slide_vec(profit, mean, .before=Inf, na.rm=T))
```

Exercise: maximum temperature to-date
===
type:prompt

```{r, warning=F, message=F}
# install.packages("devtools")
library("devtools")
# install_github("Ram-N/weatherData")
library(weatherData)
library(lubridate)
data(SFO2013)
```

```{r, tidy=F, message=F}
sfo = SFO2013 %>%
  transmute( # mutate, but drops all other columns
    time = ymd_hms(Time), 
    temp = Temperature
  ) %>%
  group_by(day = date(time)) %>%
  summarize(max_temp = max(temp))
```

Starting with this `sfo` dataframe that I've prepared for you, add a column that has the maximum temperature in the past 30 days relative to the day indicated in that row

Column-wise operations
===
type: section

Repeating operations on columns
===
```{r, tidy=F}
df = tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  g = rbinom(10,1,0.5)
)
```

- Let's say we have these data and we want to take the mean of each column `a`, `b`, and `c` within the groups `g`. 
- One way to do it is with a normal summarize:

```{r, tidy=F, message=F}
df %>%
  group_by(g) %>%
  summarize(
    mean_a = mean(a),
    mean_b = mean(b),
    mean_b = mean(c)
  )
```


***

- Copy-pasting code like this frequently creates errors and bugs that are hard to see
- It's even worse if you want to do multiple summaries

```{r, tidy=F, message=F}
df %>%
  group_by(g) %>%
  summarize(
    mean_a = mean(a),
    mean_b = mean(b),
    mean_b = mean(c),
    median_a = median(a),
    median_b = median(b),
    median_c = median(c)
  )
```

Columnwise operations
===

- The solution is to use `across()` in your summarize:
```{r, tidy=F, message=F}
df %>%
  group_by(g) %>%
  summarize(across(c(a,b,c), mean))
```

- The first argument to `across()` is a selection of columns. You can use anything that would work in a `select()` here

*** 

- The second argument is the function you'd like to apply to each column. You can provide multiple functions by wrapping them in a "`list()`". Lists are like vectors but their elements can be of different types and each element has a name (more on that later)

```{r, tidy=F, message=F}
fns = list(
  avg=mean, 
  max=max
)

df %>%
  group_by(g) %>%
  summarize(across(c(a,b), fns))
```

- see `?across()` to find out how to control how these columns get named in the output

Columnwise operations with where()
===
```{r, tidy=F}
df = tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = as.character(rnorm(10)),
  g = rbinom(10,1,0.5)
)
```

- Sometimes its nice to apply a transformation to all columns of a given type or all columns that match some condition
- `where()` is a handy function for that

```{r, tidy=F, message=F}
df %>%
  group_by(g) %>%
  summarize(across(where(is.numeric), mean))
```

Columnwise mutate
===
```{r, tidy=F}
df = tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = as.character(rnorm(10)),
  g = rbinom(10,1,0.5)
)
```

- `across()` works with any `dplyr` "verb", including `mutate()`:

```{r, tidy=F, message=F}
df %>%
  mutate(across(where(is.character), as.numeric))
```

Columnwise mutate
===
- Most often you will need to write your own mini function to do what you want. To do that you put `~` before your expression and use `.` where you would put the name of the column

```{r, tidy=F, message=F}
df %>%
  mutate(across(
    a:b,                      # columns to mutate
    ~ . - lag(.),           # function to mutate them with
    .names = '{col}_offset'   # how to name the outputs
  ))
```

- Note that I've also used the `.names` argument to control how the output columns get named

Exercise: Filtering out or replacing NAs
===
type: prompt

```{r, message=F, warning=F}
# install.packages('nycflights13')
library(nycflights13)
# glimpse(flights)
```

1. Replacing NAs with some other value is a very common operation so it gets its own function: `replace_na()`. Use this function to replace all `NA`s present in any numeric column of the flights dataset with `0`s
2. Instead of replacing these values, we may want to filter them all out instead. Starting with the original data, use `filter()` and `across()` to remove all rows from the data that have any `NA`s in any column. Recall that `is.na()` checks which elements in a vector are `NA`.

Tidy data: rearranging a data frame
============================================================
type: section

Messy data
============================================================
- Sometimes data are organized in a way that makes it difficult to compute in a vector-oriented way. For example, look at this dataset:

```{r}
head(relig_income,2)
```

- the values in the table represent how many survey respondents were of each religion and income bracket.
- How could I use ggplot to make this plot? It's hard!

```{r, echo=F, warning=F}
library(stringr)
library(ggridges)

clean = relig_income %>%
  pivot_longer(-religion, names_to="income", values_to="count") %>%
  mutate(income = ifelse(income=="Don't know/refused", NA, income)) %>%
  mutate(
    income_lower = str_extract(income, '(>150k)|(^\\$[0-9]+)'),
    income_upper = str_extract(income, '(<\\$10k)|([\\-][0-9]+)'),
  ) %>%
  mutate(across(
    starts_with('income_'), 
    ~as.numeric(str_extract(.,'[0-9]+'))
  )) %>%
  mutate(
    income_lower = if_else(!is.na(income_upper) & is.na(income_lower), -Inf, income_lower),
    income_upper = if_else(!is.na(income_lower) & is.na(income_upper), Inf, income_upper)
  ) %>%
  mutate(income = fct_reorder(income, income_lower)) %>%
  group_by(religion) %>%
  mutate(freq = count/sum(count))
```

```{r, echo=F, warning=F, fig.width=20, fig.height=5}
clean %>%
  filter(religion %in% c("Muslim", "Jewish", "Hindu", "Buddhist", "Catholic", "Atheist", "Mainline Prot")) %>%
ggplot() +
  geom_bar(aes(x=income, y=count, fill=religion), stat='identity')
```

Messy data
===
```{r}
head(relig_income,3)
```
- One of the problems with the way these data are formatted is that the income level, which is a property of a particular population, is stuck into the names of the columns. 
- Because of this, it's also not obvious what the numbers in the table mean (although we know they are counts)

Tidy data
===
- Here's a better way to organize the data:
```{r, echo=F}
tidy = relig_income %>%
  pivot_longer(-religion, names_to="income", values_to="count") 
head(tidy)
```

This data is *tidy*. Tidy data follows three precepts:

1. each "variable" has its own dedicated column
2. each "observation" has its own row
3. each type of observational unit has its own data frame

In our example, each the **observations** are different **populations**, each of which has an associated _religion_, _income_, and _count_. These are the _variables_ that are measured about the population. 

Tidy data
===

Tidy data is easy to work with.

```{r, tidy=F, warning=F, fig.width=20, fig.height=5}
tidy %>%
    filter(religion %in% c("Muslim", "Jewish", "Hindu", "Buddhist", "Catholic", "Atheist", "Mainline Prot")) %>%
ggplot() +
  geom_bar(aes(x=income, y=count, fill=religion), stat='identity')
```

Tidying data with pivot_longer()
===

- `tidyr::pivot_longer()` is the function you will most often want to use to tidy your data
```{r, tidy=F}
relig_income %>%
  pivot_longer(-religion, names_to="income", values_to="count") %>%
  head(3)
```

- the three important arguments are: a) a selection of columns, b) the name of the new key column, and c) the name of the new value column

![](https://swcarpentry.github.io/r-novice-gapminder/fig/14-tidyr-fig3.png)

Exercise: cleaning GTEX
===
type:prompt

```{r, message=F, warning=F}
gtex = read_tsv('https://raw.githubusercontent.com/alejandroschuler/r4ds-courses/advance-2020/data/gtex.tissue.zscores.advance2020.txt')
```

Use the GTEX data to reproduce the following plot:

```{r, echo=F, warning=F, fig.width=20}
gtex %>%
  filter(
    Ind %in% c('GTEX-11GSP', 'GTEX-11DXZ'),
    Gene %in% c('A2ML1', 'A3GALT2', 'A4GALT')
  ) %>%
  pivot_longer(
    Blood:Liver, 
    names_to="tissue", 
    values_to='expression'
  ) %>%
ggplot() +
  geom_point(aes(x=Gene, y=expression, color=tissue), size=10) + 
  facet_wrap(~Ind)
```

The individuals and genes of interest are `c('GTEX-11GSP', 'GTEX-11DXZ')` and `c('A2ML1', 'A3GALT2', 'A4GALT')`, respectively.

"Messy" data is relative and not always bad
===

```{r, echo=F}
wide_mice = tibble(
  mouse = c(1,2,3,4),
  weight_before = rnorm(4, 10, 2),
  weight_after = rnorm(4, 11, 2),
)
wide_mice
```

```{r, tidy=F}
wide_mice %>%
  mutate(weight_gain = weight_after - weight_before) %>%
  select(mouse, weight_gain)
```

***

```{r, echo=F}
long_mice = wide_mice %>%
  pivot_longer(-mouse, names_to="time", values_to="weight", names_prefix="weight_") %>%
  mutate()
long_mice
```

```{r, tidy=F}
long_mice %>%
  group_by(mouse) %>%
  mutate(weight_gain = weight - lag(weight)) %>%
  filter(!is.na(weight_gain)) %>%
  select(mouse, weight_gain)
```

Pivoting wider
============================================================
- As we saw with the mouse example, sometimes our data is actually easier to work with in the "wide" format. 
- wide data is also often nice to make tables for presentations, or is (unfortunately) sometimes required as input for other software packages
- To go from long to wide, we use `pivot_wider()`:

```{r, tidy=F}
long_mice
```

***

```{r, tidy=F}
long_mice %>% 
  pivot_wider(
    names_from = time, 
    values_from = weight
  )
```

Names prefix
============================================================

```{r, tidy=F}
long_mice
```

***

- you can use `names_prefix` to make variables names that are more clear in the result

```{r, tidy=F}
long_mice %>% 
  pivot_wider(
    names_from = time, 
    values_from = weight,
    names_prefix = "weight_"
  ) %>% head(2)
```

- this can also be used to _remove_ a prefix when going from wide to long:

```{r, tidy=F, eval=F}
wide_mice %>% 
  pivot_longer(
    -mouse
    names_to = "time",
    values_to = "weight",
    names_prefix = "weight_"
  )
```

Exercise: creating a table
===
type: prompt

Use the GTEX data to make the following table:

```{r, echo=F, message=F}
print("Number of missing tissues:")
gtex %>%
  filter(
    Ind %in% c('GTEX-11GSP', 'GTEX-11DXZ'),
    Gene %in% c('A2ML1', 'A3GALT2', 'A4GALT')
  ) %>% 
  pivot_longer(Lung:Liver, names_to='tissue', values_to='expression') %>%
  group_by(Ind, Gene) %>%
  summarize(n_missing_tissues = sum(is.na(expression))) %>%
  pivot_wider(names_from=Gene, values_from=n_missing_tissues)
```

The numbers in the table are the number of tissues in each individual for which the gene in question was missing.

Multi-pivoting
===
incremental: true


Have a look at the following data. How do you think we might want to make it look?

```{r, tidy=F}
data(anscombe)
anscombe
```

The problem here is that the column names contain two pieces of data:

1. the coordinate (`x` or `y`)
2. some group that it came from (`1`, `2`, `3`, or `4`)

Our use of `pivot_longer` has so far been to extract a single piece of information from the column name

Multi-pivoting
===
- Turns out this problem can be tackled too:

```{r, tidy=F}
anscombe %>%
  pivot_longer(everything(),
    names_pattern = "(.)(.)", # a "regular expression"- we'll learn about these later
    names_to = c(".value", "group")
  ) 
```

- We won't dig into this, but you should know that almost any kind of data-tidying problem can be solved with some combination of the functions in the `tidyr` package. 
- See the online [docs and vignettes](https://tidyr.tidyverse.org/articles/pivot.html) for more info

Combining multiple tables with joins
===
type:section
```{r}
# install.packages("nycflights13")
library(nycflights13)
```


Relational data
=====================================================================
class: small-code

- Relational data are interconnected data that is spread across multiple tables, each of which usually has a different unit of observation

```{r}
head(flights)
```
```{r}
head(airports)
```

***

- for instance, in these data, we have one table that describes flights, one table that describes airports, one that describes planes, and one that describes the weather. 

```{r}
head(planes)
```
```{r}
head(weather)
```

Relational data
===

- These data are not independent of each other. A plane that is described in `planes` may be referenced as taking a flight in `flights` between two airports that are described in `airports`.

<div align="center">
<img src="https://d33wubrfki0l68.cloudfront.net/245292d1ea724f6c3fd8a92063dcd7bfb9758d02/5751b/diagrams/relational-nycflights.png">
</div>

- `flights` connects to `planes` via a single variable, `tailnum`.
- `flights` connects to `airlines` through the `carrier` variable.
- `flights` connects to `airports` in two ways: via the `origin` and `dest` variables.
- `flights` connects to `weather` via `origin` (the location), and `year`, `month`, `day` and `hour` (the time).

An example join
===
- Imagine we want to add the full airline name to some columns from `flights`.
- We can accomplish that with a **join**:
```{r, tidy=F}
flights %>%
  select(tailnum, origin, dest, carrier) %>%
  inner_join(airlines, by="carrier")
```

Joins
===
```{r, tidy=F}
x = tibble(
  key = c(1,2,3),
  val_x = c("x1","x2","x3")
)
y = tibble(
  key = c(1,2,4),
  val_y = c("y1","y2","y3")
)
```

<div align="center">
<img src="https://d33wubrfki0l68.cloudfront.net/108c0749d084c03103f8e1e8276c20e06357b124/5f113/diagrams/join-setup.png">
</div>

***

```{r}
inner_join(x, y, by="key")
```
- An inner join matches pairs of observations when their "keys" are equal
- the column that is joined on is specified as a "key" with the argument `by="column"`

<div align="center">
<img src="https://d33wubrfki0l68.cloudfront.net/3abea0b730526c3f053a3838953c35a0ccbe8980/7f29b/diagrams/join-inner.png">
</div>

Duplicate keys
===
```{r}
x <- tibble(
  key = c(1,2,2,3),
  val_x = c("x1","x2","x3","x4")
)
y <- tibble(
  key = c(1,2,2,4),
  val_y = c("y1","y2","y3","y4")
)
```

<div align="center">
<img src="https://d33wubrfki0l68.cloudfront.net/d37530bbf7749f48c02684013ae72b2996b07e25/37510/diagrams/join-many-to-many.png">
</div>

***

```{r}
inner_join(x, y, by="key")
```

When keys are duplicated, multiple rows can match multiple rows, so each possible combination is produced

Specifying the keys
===
```{r}
inner_join(airports, flights, by="origin")
```
- Why does this fail?

Specifying the keys
===
- When keys have different names in different dataframes, the syntax to join is:
```{r}
inner_join(airports, flights, by=c("faa"="origin"))
```

Exercise: finding planes
===
Use joins to find the distinct models of airplane that fly into Seattle Tacoma Intl.


Other joins
===

<div align="center">
<img src="https://d33wubrfki0l68.cloudfront.net/9c12ca9e12ed26a7c5d2aa08e36d2ac4fb593f1e/79980/diagrams/join-outer.png">
</div>

***

- A left join keeps all observations in `x`.
- A right join keeps all observations in `y`.
- A full join keeps all observations in `x` and `y`.

<div align="center">
<img src="https://d33wubrfki0l68.cloudfront.net/aeab386461820b029b7e7606ccff1286f623bae1/ef0d4/diagrams/join-venn.png">
</div>

- Left join should be your default
  - it looks up additional information in other tables
  - preserves all rows in the table you're most interested in

Joining on multiple columns
===
- It is often desirable to find matches along more than one column
```{r}
flights %>%
  select(tailnum, year:day, hour, origin) %>%
  left_join(weather, by=c("year", "month", "day", "hour", "origin")) %>%
  head(3)
```
- This is also possible if the columns have different names
```{r, eval=F}
flights %>%
  select(tailnum, year:day, hour, origin) %>%
  rename(departure = origin) %>%
  left_join(weather, by=c("year", "month", "day", "hour", "departure"="origin"))
```

Join problems
===
- Joins can be a source of subtle errors in your code
- check for `NA`s in variables you are going to join on
- make sure rows aren't being dropped if you don't intend to drop rows
  - checking the number of rows before and after the join is not sufficient. If you have an inner join with duplicate keys in both tables, you might get unlucky as the number of dropped rows might exactly equal the number of duplicated rows
- `anti_join()` and `semi_join()` are useful tools (filtering joins) to diagnose problems
  - `anti_join()` keeps only the rows in `x` that *don't* have a match in `y`
  - `semi_join()` keeps only the rows in `x` that *do* have a match in `y`

Exercise: nonexistent planes
====
type: prompt

It appears some of the `tailnum`s in `flights` do not appear in `planes`. Is there something those flights have in common that might help us diagnose the issue? See if you can find some other variable that correlates or somehow explains this missingness. Use any tools you like.
